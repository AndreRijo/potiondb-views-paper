\documentclass{vldb}

\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{paralist}
\usepackage[inline]{enumitem}



\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)


\newcommand{\grumbler}[2]{{\color{red}{\bf #1:} #2}}
\newcommand{\andre}[1]{\grumbler{andre}{#1}}
\newcommand{\nuno}[1]{\grumbler{nuno}{#1}}
\newcommand{\carla}[1]{\grumbler{carla}{#1}}

\newcommand{\outline}[1]{}
%\newcommand{\outline}[1]{\grumbler{outline}{#1}}

\vldbTitle{}
\vldbAuthors{}
\vldbVolume{12}
\vldbNumber{xxx}
\vldbYear{2020}
\vldbDOI{https://doi.org/TBD}


\begin{document}

\title{Global Views on Partially Geo-Replicated Data}
\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.

\author{\alignauthor André Rijo\\
       \affaddr{NOVA LINCS, FCT, Universidade NOVA de Lisboa}\\
%       \email{v.sousa@campus.fct.unl.pt}
\alignauthor Carla Ferreira\\
       \affaddr{NOVA LINCS, FCT, Universidade NOVA de Lisboa}\\
%       \email{carla.ferreira@fct.unl.pt}
\alignauthor
Nuno Preguiça\\
       \affaddr{NOVA LINCS, FCT, Universidade NOVA de Lisboa}\\
%       \email{nuno.preguica@fct.unl.pt}
}


\maketitle

\begin{abstract}
bla

bla

bla

bla

bla

bla

bla

bla

\end{abstract}

\section{Introduction}

%	\item Num. DC a aumentar

The increasing reliance on web service in many domains of activity, from e-commerce to business applications
and entertainment, leads to stringent requirements regarding latency, availability and fault tolerance \cite{Schurman2009latency,gomez}.
To address these requirements, cloud platforms have been adding new data centers at different geographic 
locations. By allowing users to access a service by contacting the closest data center, a global service can
provide low latency to users spread across the globe. The increasing number of data centers also contributes
for proving high availability and fault tolerance, by allowing a user to access the service by accessing any
available data center.

% serviços necessitam de data
% Replicar totalmente tem problemas

The database is a key component of any web service, storing the service's data. For supporting global
services running at multiple geographic locations, it is necessary to rely on a geo-replicated database \cite{dynamo},
which maintains replicas of the data at the data centers where the service is running.
A number of geo-replicated database have been proposed, providing different consistency semantics.
Databases that provide strong consistency \cite{spanner,cockroachdb,mdcc} intend to give  the illusion that 
a single replica exists, requiring coordination among
multiple replicas for executing (update) operations. This leads to high latency and may compromise 
availability int he presence of network partitions.
Database that provide weak consistency \cite{eventual,dynamo,cops} allow any replica to process a
client request, leading to lower latency and high availability. As a consequence, these databases expose
temporary state divergence to clients, making it more difficult to program a system. 

In either case, geo-replicated databases typically rely on a full replication model, where each data 
center replicates the full database, with data being sharded across multiple partitions in each data 
center. 
As both the data managed by these systems increases in size and the number of data centers increases,
this approach leads to a number of problems.
First, storing all data in all data centers imposes a large overhead in terms of storage. 
Furthermore, storing some data in all data centers may be unnecessary, as data is only needed at some
geographic locations.
Second, increasing the number of data centers makes the replications process more complex and costly, 
as each update needs to be propagated to all other data centers.

For addressing these problems, partial replication is an attractive approach, with each data center
replicating only a subset of the data. A number of works have been addressing the challenges of 
partial replication, for example by proposing algorithms to manage partially replicated data \cite{more,saturn,c3}
and to decide which data is replicated in which replica \cite{}.

In this paper we address the problem of querying data in a weakly consistent partially geo-replicated database, 
focusing on recurrent queries for which a programmer would want to generate a (materialized) view.
For example, consider an e-commerce system with users from multiple geographic locations.
In this case, the data pertaining users of a given location do not need to be replicated in all data centers
(but only in a few for fault tolerance). The same applies to other information, such as data on orders and 
warehouses.
Other data, such as information on products would be replicated in the regions where the product
is available.  
Under this data placement, obtaining the list of best seller products is challenging, as it requires
accessing data that is located at multiple data centers.

Several possible solutions exist for this problem. 
First, it is possible to have a data center that replicates all data, and forward these queries to such data center.
Doing this imposes a latency penalty and requires a data center to host all data and execute all queries of this type. 
Second, it is possible to execute the query by accessing multiple locations, by using, for example, 
a distributed processing system with support for geo-partitioned data \cite{Kloudas:2015:POD:2850578.2850582,more}.
This approach requires running an additional external service and poses challenges for the consistency of the results
returned and the data observed by users.
%, mostly when adopting weak consistency models (a local update that should
%be reflected in the result of the query may not be returned, as the update might have not been read by the 
%external service that accessed a different replica).

We propose a different approach: to maintain materialized views, as commonly available in relational databases.
Implementing such feature efficiently in a partially geo-replicated database requires 
addressing two main challenge challenges. 
First, it is necessary to guarantee consistency between the base data available in a replica and the 
relevant materialized views. To achieve this, we designed a replication mechanism where updates 
to the base data and views are made visible atomically in each replica.

Second, it is necessary to efficiently support views with limits, used for example to support \emph{top-k} 
queries. To achieve this, we build on the concept of non-uniform replication \cite{Cabrita17Nonuniform}, in which the state
of different replicas may be different, given that the observable state is (eventually) the same.
This allows each replica to propagate only the updates that might be relevant to the observable 
state. Providing support for views required us to extend non-uniform replication from simple data 
types to more complex structures that could support a view with multiple columns.
\nuno{can we support updates to the views? why not?}

We present the design and implementation of PotionDB, a geo-replicated key-value store with support  
for partial replication and materialized views. 
PotionDB provides weak consistency, for improved latency and availability, and support for highly
available transactions \cite{hat}.  
To our knowledge, our work is the first to address the problem of maintaining materialized views
in such setting.  

We have evaluated our system using micro-benchmarks and TPC-H queries \cite{} \nuno{TPC-H, certo?}.
The results show that our algorithms for maintaining materialized views impose 
low overhead when executing and asynchronously replicating transactions, particularly
for views with limits.
\nuno{deviamos ter uns micro-benchmarks que comparassem o overhead com limites e sem limites}
Additionally, the results show that executing queries by relying on the materialized views is much more 
efficient than using alternative mechanisms.  
Furthermore, our algorithms for maintaining materialized views in a decentralized way perform better 
that alternative approaches where the view is computed in a single data center, while being
able to  keep consistency between the base and view data in every replica.

In this paper we make the following contributions:
%\begin{enumerate*}[label=(\roman*)]
\begin{itemize}
	\item the design of a geo-replicated key-value store  with support for partial replication
	and views over partially replicated data; 
	\item replication algorithms for efficiently maintaining consistent materialized views over 
	partially replicated data;
	 \item an implementation and evaluation of the proposed approach with micro-benchmarks
	 and TPC-H.
\end{itemize}

The remainder of the paper is organized as follows. Section ...

\outline{topicos

\begin{itemize}
	\item Num. DC a aumentar
	\item Replicar totalmente tem problemas
	\item Replicação parcial
	\item Queries sobre dados replicados parcialmente
	\begin{itemize}
		\item Standard solution?
	\end{itemize}
	\item Views materializadas replicadas totalmente
	\item Contribuições
\end{itemize}
}

\section{System overview}

\begin{itemize}
	\item System model
	\begin{itemize}
		\item Replicação parcial
	\end{itemize}
	\item System API
	\begin{itemize}
		\item "Create table"
		\item "Create view"
		\begin{itemize}
			\item CRDT não uniforme
			\item put numa table $\implies$ puts nas várias views
			\begin{itemize}
				\item consistência das views face aos dados - in sync
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item System description
	\begin{itemize}
		\item CRDT não uniforme
		\item Implementação de queries?
	\end{itemize}

\end{itemize}

\section{Implementation}

\section{Evaluation}

\section{Related Work}

\section{Conclusions}


\bibliographystyle{abbrv}
\bibliography{bib}

\section{System overview}

\vspace{8cm}
Possiveis pontos mais detalhados?

\subsection{System model}

\begin{itemize}
	\item Network assumptions
	\item Client-server interaction (refer key-value store interface? Maybe refer this instead in System API?)
	\item Server-server interaction? (is it needed? We'll already touch this in Replication.)
	\item System guarantees
	\begin{itemize}
		\item CRDTs
		\item Consistency level	
	\end{itemize}
	\item Replication
		\item Async
		\item Op-based
		\item Maintains consistency, i.e., transaction level based.
		\item Partial (system admin defined, each server only has a subset of the data based on topics. Potencially some data can be replicated everywhere)
\end{itemize}

\subsection{System API}

\begin{itemize}
	\item Basically how can we translate a problem to sql-like operations
	\item Create table
	\item Create view
	\item Updates (incluir problema de consistência de views/dados)
	\item Queries (incluir aqui problema de os CRDTs não uniformes precisarem de mais dados? Ou na zona da view?)
\end{itemize}

\subsection{System description}

\begin{itemize}
\item Structure? Maybe that's for implementation? How much detail?
\begin{itemize}
	\item Internal partitioning vs external partitioning? Capaz de não ser boa ideia...	
\end{itemize}
\item CRDTs and non-uniform CRDTs?
\end{itemize}

\section{Implementation}

\begin{itemize}
	\item Go
	\item Transactions (TM/Mat?)
	\item Replication (RabbitMQ and other stuff?)
	\item Communication (protobufs. Also worth noticing the compability with existing AntidoteDB clients)
	\item CRDTs (version management at least)
\end{itemize}

\null\newpage

\section{System Overview}

\subsection{System model}

We consider an asynchronous distributed system composed by a set of servers S connected by a network. We assume the network may delay, duplicate or re-order messages, but does not corrupt them. We also assume messages sent are eventually delivered, even if connections may temporarely drop.

Database objects are replicated in one or more servers, but not necessarely in all of them.  We consider a server to be a replica of an object if it replicates such object. New updates are sent periodically to replicas asynchrnously. However, not all updates need to be delivered to every replica - only updates that modify the objects' visible state must be delivered eventually \ref{non-uniform}. %TODO: The phrase before needs to be worked on.

%TODO: I also need to talk here about consistency
%Partial order?

Clients connect to one or more servers. Updates and queries are executed in a single server and return as soon as its execution ends. Only objects replicated in the server can be accessed, i.e., to access objects not present in a given server the client must connect to a replica of those objects.

\subsection{[PLACEHOLDER]Example scenario}
\label{subsec:example}
%TODO: Talk about partial replication before this

For the rest of this paper/section %TODO: Decide
, we'll consider the following example scenario.

Assume we have a very large company with multiple stores across the world.
Consider that there's millions of products (each store has a different stock and may sell different items), and tens of millions of clients.
Also consider that, for both product warranty and statistical purposes, data related to each product unit sold is kept in the database.

Fully replicating the whole dataset would have proibitive costs.
It is also unecessary, as the relevance of the data (and likehood of being accessed from) is dependent on the location.
For instance, an asian customer is more likely to consult the stock of stores in his country than in an european country.
Thus, it makes sence that both asian customers' data and asian stores' to be replicated mainly in asian datacenters (plus possibility a subset of others for fault tolerance purposes).
That is, the servers for which data will be replicated can be choosen based on the geographic location, as its relevance depends on that.

To simplify the example, we'll consider only three types of objects: customers, products and sales.
The simplified scheme of each object can be found on Figure \ref{fig:objects}.\\

Customer: id: int, name: string, age: int, country: string \\
Products: id: int, name: string, value: int \\
Sales: id: int, custID: int, productID: int, amount: int \\

\begin{figure}
	\label{fig:objects}
%\begin{table}[]
	\begin{tabular}{|l|l|}
		\multicolumn{2}{c}{Customer} \\ \hline
		id            & int          \\ \hline
		name          & string       \\ \hline
		age           & int          \\ \hline
		country       & string      \\
		\hline
	\end{tabular}
	\raisebox{0.225\height}{\begin{tabular}{|l|l|}
		\multicolumn{2}{c}{Products} \\ \hline
		id           & int           \\ \hline
		name         & string        \\ \hline
		value        & int   \\
		\hline       
	\end{tabular}}
	\begin{tabular}{|l|l|}
		\multicolumn{2}{c}{Sales} \\ \hline
		id            & int       \\ \hline
		custID        & string    \\ \hline
		productID     & int       \\ \hline
		amount        & int	\\
		\hline      
	\end{tabular}
	\caption{Example objects}
%\end{table}
\end{figure}

Customers represent clients that at some point in time have bought at least one product from one of the stores.
Products represents items that may be (or have been) for sale.
Sales represents the aquisition of one or more units of a product by a client, where custID and productID refer to, respectivelly, the customer's and product's id field.

For the purpose of this example, we'll consider the following replication scheme for each type of object:
\begin{itemize}
	\item \emph{Customer:} partially replicated in the data centers present in the continent correspondent to its country;
	\item \emph{Products:} replicated in all datacenters
	\item \emph{Sales:} partially replicated in the same datacenters as of the customer who bought the product. 
\end{itemize}

Note that each object being partially replicated does not prevent queries that refer to data replicated in different datacenters from being executed.
On section ??? %TODO
we'll see how can this be done efficiently.

\subsection{System API}

\subsubsection{Key-value store API}

%TODO: Some connection with the topic before.
%TODO: Proper formatting of GET/UPDATE/LINK structures/examples
PotionDB is a key-value store database. %TODO: Reference?
As such, all objects are indexed by a key and support  \emph{get} and \emph{update} operations which, respectively, return/alter the state of the object.
In PotionDB objects are CRDTs, %TODO: Reference? 
which ensures that even if objects are modified concurrently in different replicas, their states will eventually converge.
As such, both \emph{get} and \emph{update} operations are executed locally, with the effects of \emph{updates} being propagated asynchronously to other replicas.

To facilitate development of applications that want to use PotionDB, both \emph{gets} and \emph{updates} may refer to either the full object state or part of it.
A \emph{get} has the following structure for, respectively, full/partial reads: \\

%TODO: Include a comment in front of each one stating which is full and which is partial read. Likely use an array/table to properly set the spacing?
Get CRDT key bucket crdtType 

Get CRDT key bucket crdtType\{arguments\} \\ 

The triple key, bucket, crdtType uniquely identify an object. 
Bucket is used mainly for partial replication purposes, as described in Section ???. %TODO
Arguments can be supplied when only a part of the state needs to be returned, with the possible arguments depending on the type of CRDT. E.g., for a map CRDT, we could use: \\

Get CRDT customer1 customers MAP\{name, age\}\\

to return only the values in the customer1 map CRDT referred by the map keys name and age.

As for updates, they have the following form: \\

Update CRDT key bucket crdtType\{arguments\} \\

Key, bucket and crdtType have the same meaning as in gets.
The type of arguments depend on the type of CRDT, and each CRDT can support one or more types of update operations. 
E.g., a map supports both addition and removal of key/value pairs.
An insertion/update of an entry in a map can be represented as: \\

Update CRDT customer1 customers MAP\{ADD\{name: "David"\}\} \\

\subsubsection{API for view CRDTs}
%TODO: We ALMOST SURELY need a section before this explaining what is partial replication, it's advantages/disadvantages, why we use it and why views are interesting for that.
%TODO: This may be more fit to another section, or split in multiple subsections in different sections of the paper

In relational databases (and even some non-relational ones, e.g., Cassandra) it's common to have \emph{Views}. 
A view can be defined as being the result of a query on one or multiple objects.
Views can then be accessed as if they were normal objects, thus facilitating the definition of new queries.
%TODO: Does this need a SQL example here?

Views can either be materialized or not (albeit not all databases support both). %TODO: references 
In a materialized view, the result of the query is stored as an object, which can then be reused later.
This can potencially improve drastically the performance of certain queries, but incours an extra cost on object updates, as both the object and the materialized view need to be updated.
On the other hand, non-materialized views don't have this extra cost, but they also don't usually improve the performance of queries, as their result is re-calculated on each query.

In PotionDB, it is particularly interesting to support materialized views.
To ilustrate that, recall the example tables and scenario defined in Section \ref{subsec:example}, along with the following query: 
%TODO: Do some proper emphasis on this
%TODO: Also consider doing this only for a continent instead of globally.

\emph{Determine the 100 customers who have spent the most across all stores. For each customer, the name, age, country and total value spent must be returned.}

Without a view, to implement this query it would be necessary to communicate with datacenters across the whole world (as sales and customers are partitioned). 
Since there are millions of customers and sales, we would not only need to download large amounts of data but also do long data joins,
Only after calculating the total value spent for each customer in the service would we be able to reply with the top 100 customers.
Due to the sheer amount of data involved, this would have unnaceptable performance.

A possible solution is to use a Top-K CRDT %TODO: ref to NuCRDTs paper
as a materialized view which keeps the list of the 100 customers with highest (global) spendings.
This way, the query could be answered by executing only one \emph{get} operation on this CRDT.
This solution does pose some difficulties, namelly: 
%associate; keep entries updated even if the CRDT referred is not replicated locally; have new customers/sales be automatically included in the top-k.
\begin{enumerate*}[label=(\roman*)]
	\item association of each entry in the top-k with the respective customer and sales' CRDTs;
	\item translation of updates in customers or sales to updates for the top-k;
	\item keeping top-k updated even if some entries refer to CRDTs not replicated in the replica in which the top-k is created;
	\item automatically include customer and sales CRDTs that may be introduced after the creation of the top-k.
\end{enumerate*}

To support materialized views, we thus introduce another construct in our API, named \emph{link}.
The intuitive idea is that, after creating the CRDT that will be acting as a view, we can issue a \emph{link} operation in order to provide the "rules" for the automatic updating of the referred CRDT.
PotionDB will then use these "rules" to keep the CRDT updated.

A link operation has the following structure:

%TODO: Need to think on a better way to represent this. Also, either separate this in parts or in lines at least

Link CRDT key bucket crdtType ...
\\
Link CRDT topsales statistics \\
	Search CRDT sales * sales, MAP \\
	Get CRDT MAP\{custID, amount\} \\
	Get CRDT MAP\{id, value\} \\
	Merge custID = id \\
	Update 
	

\textbf{NOTE: PLACEHOLDER TEXT THAT WILL CERTAINTLY HAVE TO BE REWORKED.} I just wanted to get some more work done until I figure out a way to better represent the "link" command :)



\subsection{System description}



\null\newpage\null

\null\newpage\null

\end{document}
